import os, json, re, asyncio, sys
import requests
from bs4 import BeautifulSoup
from playwright.async_api import async_playwright
from manager import save_to_db, enrich_db_with_tags_high_speed, analyze_text_with_llm
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

# ì €ì¥ ìœ„ì¹˜ ì„¤ì • (main.pyì™€ ê³µìœ í•  DB ê²½ë¡œ)
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

def normalize_product_data(item: dict) -> dict:
    """
    ìƒí’ˆëª…, í–‰ì‚¬ë‚´ìš©, ë‹¨ìœ„ í•„ë“œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ íƒìƒ‰í•˜ì—¬ 
    ìš©ëŸ‰(capacity_ml)ê³¼ 100ë‹¨ìœ„ë‹¹ ê°€ê²©(unit_price_per_100)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    p_name = item.get("product_name", "")
    price = item.get("final_price", 0)
    condition = item.get("discount_condition", "")
    unit_field = item.get("unit", "")
    
    # 1. íƒìƒ‰í•  í…ìŠ¤íŠ¸ í›„ë³´êµ° (ìˆœì„œ ì¤‘ìš”: ìƒí’ˆëª… -> í–‰ì‚¬ë‚´ìš© -> ë‹¨ìœ„)
    # Noneì´ ë“¤ì–´ì˜¬ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬
    search_targets = [
        str(p_name), 
        str(condition), 
        str(unit_field)
    ]
    
    capacity = 0
    
    # ì •ê·œì‹: ì†Œìˆ˜ì  ì§€ì› (1.1kg), ëŒ€ì†Œë¬¸ì ë¬´ì‹œ
    # ì˜ˆ: 1.5L, 200ml, 500g, 1kg
    pattern = r'(\d+(?:\.\d+)?)\s*(ml|l|g|kg)'
    
    for text in search_targets:
        match = re.search(pattern, text.lower())
        if match:
            value = float(match.group(1))
            unit = match.group(2)
            
            # ë‹¨ìœ„ ë³€í™˜ (L, kg -> 1000ë°°)
            if unit in ['l', 'kg']:
                capacity = int(value * 1000)
            else:
                capacity = int(value)
            
            # ë¬¶ìŒ ìƒí’ˆ ì²´í¬ (x3, *3ì… ë“±) - í•´ë‹¹ í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ì°¾ê¸°
            bundle_match = re.search(r'[\*x]\s*(\d+)', text.lower())
            if bundle_match:
                count = int(bundle_match.group(1))
                capacity *= count
            
            # ìš©ëŸ‰ì„ ì°¾ì•˜ìœ¼ë©´ ë£¨í”„ ì¤‘ë‹¨ (ë” ì´ìƒ ë’¤ì§ˆ í•„ìš” ì—†ìŒ)
            break

    # 2. ì‹¤ì§ˆ ê°€ê²© ë° ìš©ëŸ‰ ê³„ì‚° (í–‰ì‚¬ ë°˜ì˜)
    total_capacity = capacity
    pay_price = price
    
    # í–‰ì‚¬ ë‚´ìš©(condition)ì€ ì–´ë””ì„œ ìš©ëŸ‰ì„ ì°¾ì•˜ë“  í•­ìƒ ì°¸ì¡°í•´ì•¼ í•¨
    cond_lower = str(condition).lower()
    
    if "1+1" in cond_lower:
        total_capacity = capacity * 2
    elif "2+1" in cond_lower:
        total_capacity = capacity * 3
        pay_price = price * 2

    # 3. ë°ì´í„° ì£¼ì…
    if total_capacity > 0:
        # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        item["unit_price_per_100"] = int((pay_price / total_capacity) * 100)
        item["capacity_ml"] = capacity
    else:
        # ìš©ëŸ‰ íŒŒì•… ë¶ˆê°€ ì‹œ
        item["unit_price_per_100"] = 0
        item["capacity_ml"] = 0
        
    return item

# --- [ë„êµ¬ 1] GS ë”í”„ë ˆì‹œ í¬ë¡¤ëŸ¬ ---
async def get_gs_the_fresh_deals():
    """GS ë”í”„ë ˆì‹œ ì „ë‹¨ì§€ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³  ì €ì¥í•©ë‹ˆë‹¤."""
    url = "https://web.gsretail.me/Viewer/gsp2/"
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        try:
            await page.goto(url, wait_until="networkidle")
            await asyncio.sleep(2) 
            await page.wait_for_selector("img.pageImage", timeout=20000)            
            
            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')
            images = soup.find_all("img", class_="pageImage")
            raw_texts = [img.get("aria-label") for img in images if img.get("aria-label")]
            
            if not raw_texts:
                await browser.close()
                return "GS ë”í”„ë ˆì‹œ: ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨ (aria-label ë¹„ì–´ìˆìŒ)"

            full_text = "\n\n".join(raw_texts)
            lines = [line.strip() for line in full_text.split('\n') if line.strip()]
            
            chunk_size = 15 
            chunks = ["\n".join(lines[i:i + chunk_size]) for i in range(0, len(lines), chunk_size)]
            tasks = [analyze_text_with_llm("GS The Fresh", chunk) for chunk in chunks]
            chunk_results_json = await asyncio.gather(*tasks)
            
            all_extracted_items = []
            for res_json in chunk_results_json:
                try:
                    data = json.loads(res_json)
                    if isinstance(data, dict) and "items" in data:
                        all_extracted_items.extend(data["items"])
                    elif isinstance(data, list):
                        all_extracted_items.extend(data)
                except: continue
            
            final_items_dict = {}  # {ìƒí’ˆëª…: ìƒí’ˆë°ì´í„°} êµ¬ì¡°ë¡œ ì €ì¥í•˜ì—¬ ì¤‘ë³µ ë°©ì§€

            for item in all_extracted_items:
                name = item.get("product_name", "").strip()
                if not name: continue
                
                # ê³µë°± ì œê±°í•œ ì†Œë¬¸ì ì´ë¦„ì„ í‚¤ë¡œ ì‚¬ìš©
                unique_key = name.replace(" ", "").lower()
                
                # [ìˆ˜ì •] ê°€ê²© ë°ì´í„° íƒ€ì… ì•ˆì „í•˜ê²Œ ë³€í™˜
                def safe_int(val):
                    if isinstance(val, int): return val
                    try:
                        # ìˆ«ì ì™¸ì˜ ë¬¸ì(ì›, ,, ê³µë°± ë“±) ì œê±° í›„ ì •ìˆ˜ ë³€í™˜
                        import re
                        return int(re.sub(r'[^0-9]', '', str(val)))
                    except:
                        return 999999 # ë³€í™˜ ì‹¤íŒ¨ ì‹œ í° ê°’ ë¶€ì—¬

                current_price = safe_int(item.get("effective_unit_price", 999999))
                # ë¹„êµë¥¼ ìœ„í•´ ì›ë³¸ ë°ì´í„°ì˜ íƒ€ì…ë„ ì •ìˆ˜ë¡œ ì—…ë°ì´íŠ¸í•´ë‘ë©´ ì¢‹ìŠµë‹ˆë‹¤.
                item["effective_unit_price"] = current_price

                if unique_key in final_items_dict:
                    # ì´ì œ ë‘ ê°’ ëª¨ë‘ í™•ì‹¤í•œ intì´ë¯€ë¡œ ì—ëŸ¬ê°€ ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
                    existing_price = final_items_dict[unique_key].get("effective_unit_price", 999999)
                    if current_price < existing_price:
                        final_items_dict[unique_key] = item
                else:
                    final_items_dict[unique_key] = item

            # ë”•ì…”ë„ˆë¦¬ë¥¼ ë‹¤ì‹œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            all_extracted_items = list(final_items_dict.values())
            # --- [ì¤‘ë³µ ì œê±° ë¡œì§ ì¢…ë£Œ] ---

            await browser.close()
            save_to_db("gs_the_fresh", all_extracted_items)
            return f"GS ë”í”„ë ˆì‹œ ì™„ë£Œ: {len(all_extracted_items)}ê°œ (ì¤‘ë³µ ì œê±° ì™„ë£Œ)"

        except Exception as e:
            await browser.close()
            return f"GS ë”í”„ë ˆì‹œ ì—ëŸ¬: {e}"

# --- [ë„êµ¬ 2] ì´ë§ˆíŠ¸ í¬ë¡¤ëŸ¬ ---
async def get_emart_deals():
    """ì´ë§ˆíŠ¸ ì „ë‹¨ì§€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    url = "https://store.emart.com/news/leafletfull.do?division=2"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        resp = requests.get(url, headers=headers)
        soup = BeautifulSoup(resp.text, 'html.parser')
        hidden_divs = soup.find_all("div", class_="hide")
        all_text = "".join([div.get_text(separator="\n").strip() + "\n" for div in hidden_divs])
        lines = [l.strip() for l in all_text.split('\n') if l.strip()]
        
        total_items = []
        chunk_size = 35 
        tasks = [analyze_text_with_llm("Emart", "\n".join(lines[i : i + chunk_size])) for i in range(0, len(lines), chunk_size)]
        results = await asyncio.gather(*tasks)

        for result_json in results:
            data = json.loads(result_json)
            total_items.extend(data.get("items", []))

        save_to_db("emart", total_items)
        return f"ì´ë§ˆíŠ¸ ì™„ë£Œ: {len(total_items)}ê°œ"
    except Exception as e:
        return f"ì´ë§ˆíŠ¸ ì—ëŸ¬: {e}"

# --- [ë„êµ¬ 3] CU í¬ë¡¤ëŸ¬ ---
async def get_cu_deals():
    """CU APIë¥¼ í†µí•´ 1+1, 2+1 ìƒí’ˆì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    api_url = "https://cu.bgfretail.com/event/plusAjax.do"
    final_items = []
    seen_names = set()
    event_configs = [{"code": "23", "label": "1+1"}, {"code": "24", "label": "2+1"}]
    
    for config in event_configs:
        page = 1
        while page <= 60:
            payload = {"pageIndex": page, "listType": 0, "searchCondition": config["code"]}
            response = requests.post(api_url, data=payload)
            soup = BeautifulSoup(response.text, 'html.parser')
            prod_elements = soup.find_all("li", class_="prod_list")
            
            if not prod_elements: break
            
            new_count = 0
            for prod in prod_elements:
                name = prod.find("div", class_="name").get_text(strip=True)
                unique_key = f"{name}_{config['label']}"
                if unique_key not in seen_names:
                    seen_names.add(unique_key)
                    new_count += 1
                    price = int(prod.find("div", class_="price").strong.get_text(strip=True).replace(",", ""))
                    img_tag = prod.find("img", class_="prod_img")
                    image_url = ("https:" + img_tag["src"]) if img_tag and img_tag["src"].startswith("//") else (img_tag["src"] if img_tag else "")
                    
                    if config['label'] == "1+1":
                        # 1ê°œ ê°€ê²©ìœ¼ë¡œ 2ê°œë¥¼ ê°€ì ¸ì˜´
                        sale_price = price  
                        effective_unit_price = price // 2
                    elif config['label'] == "2+1":
                        # 2ê°œ ê°€ê²©ìœ¼ë¡œ 3ê°œë¥¼ ê°€ì ¸ì˜´
                        sale_price = price * 2
                        effective_unit_price = (price * 2) // 3
                    else:
                        # ì¼ë°˜ í• ì¸ ë“±
                        sale_price = price
                        effective_unit_price = price

                    # 2. ë°ì´í„° ì¶”ê°€
                    final_items.append({
                        "product_name": name,
                        "original_price": price,            # ìƒí’ˆ 1ê°œì˜ ì›ë˜ ê°€ê²©
                        "sale_price": sale_price,            # í–‰ì‚¬ ì°¸ì—¬ë¥¼ ìœ„í•œ ì‹¤ì œ ê²°ì œ ì´ì•¡
                        "effective_unit_price": effective_unit_price,  # í˜œíƒ ì ìš© í›„ 1ê°œë‹¹ ì‹¤ì§ˆ ë‹¨ê°€
                        "discount_condition": config['label'],
                        "image_url": image_url
                    })
            if new_count == 0: break
            page += 1
            await asyncio.sleep(0.05)
            
    save_to_db("cu", final_items)
    return f"CU ì™„ë£Œ: {len(final_items)}ê°œ"

# --- [ë„êµ¬ 4] GS25 í¬ë¡¤ëŸ¬ ---
async def get_gs25_deals():
    """GS25 1+1, 2+1 ìƒí’ˆ ì „ìˆ˜ ìˆ˜ì§‘"""
    url = "http://gs25.gsretail.com/gscvs/ko/products/event-goods"
    api_url = "http://gs25.gsretail.com/gscvs/ko/products/event-goods-search"
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        try:
            await page.goto(url, wait_until="networkidle")
            content = await page.content()
            token = content[content.find('name="CSRFToken" value="')+24 : ].split('"')[0]
            all_items = []
            events = {"ONE_TO_ONE": "1+1", "TWO_TO_ONE": "2+1"}

            for event_key, event_name in events.items():
                p_num = 1
                while True:
                    raw_res = await page.evaluate(f"""
                        async () => {{
                            const r = await fetch('{api_url}', {{
                                method: 'POST',
                                headers: {{ 'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8' }},
                                body: 'pageNum={p_num}&pageSize=50&parameterList={event_key}&CSRFToken={token}'
                            }});
                            return await r.text();
                        }}
                    """)
                    data = json.loads(raw_res)
                    if isinstance(data, str): data = json.loads(data)
                    items_list = data.get("results", [])
                    if not items_list: break

                    for item in items_list:
                        price = item.get("attPrice") or item.get("price") or 0
                        if isinstance(price, str): price = int("".join(filter(str.isdigit, price)))
                        all_items.append({
                            "product_name": item.get("goodsNm", ""),
                            "original_price": price,
                            "sale_price" : price if event_key == "ONE_TO_ONE" else (price*2),
                            "unit_effective_unit_price": price // 2 if event_key == "ONE_TO_ONE" else (price * 2) // 3,
                            "discount_condition": event_name,
                            "image_url": item.get("attFileNm") or item.get("attFileNmOld", "")
                        })
                    p_num += 1
                    if len(items_list) < 50: break

            save_to_db("gs25", all_items)
            await browser.close()
            return f"GS25 ì™„ë£Œ: {len(all_items)}ê°œ"
        except Exception as e:
            await browser.close()
            return f"GS25 ì—ëŸ¬: {e}"

# --- [ë„êµ¬ 5] ì„¸ë¸ì¼ë ˆë¸ í¬ë¡¤ëŸ¬ ---
async def get_seven_eleven_deals():
    """ì„¸ë¸ì¼ë ˆë¸ ì •ë°€ ìˆ˜ì§‘"""
    api_url = "https://www.7-eleven.co.kr/product/listMoreAjax.asp"
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        try:
            await page.goto("https://www.7-eleven.co.kr/product/presentList.asp")
            all_items = []
            for p_tab in [1, 2, 4]:
                curr_page = 1
                while curr_page <= 100:
                    raw_html = await page.evaluate(f"""
                        async () => {{
                            const r = await fetch('{api_url}', {{
                                method: 'POST',
                                headers: {{ 'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8' }},
                                body: 'intCurrPage={curr_page}&intPageSize=10&pTab={p_tab}'
                            }});
                            return await r.text();
                        }}
                    """)
                    if "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤" in raw_html: break
                    soup = BeautifulSoup(raw_html, 'html.parser')
                    li_tags = soup.find_all("li")
                    if not li_tags: break

                    for li in li_tags:
                        name_el = li.select_one(".name")
                        if not name_el: continue
                        price = int("".join(filter(str.isdigit, li.select_one(".price").get_text())))
                        tag = li.select_one(".tag_list_01 li").get_text(strip=True) if li.select_one(".tag_list_01 li") else "í–‰ì‚¬"
                        if "ë¤" in tag: continue
                        
                        all_items.append({
                            "product_name": name_el.get_text(strip=True),
                            "original_price": price,
                            "sale_price" : price if "1+1" in tag else price*2 if "2+1" in tag else price,
                            "unit_effective_unit_price": price // 2 if "1+1" in tag else (price * 2) // 3 if "2+1" in tag else price,
                            "discount_condition": tag,
                            "image_url": "https://www.7-eleven.co.kr" + li.select_one("img")["src"] if li.select_one("img") else ""
                        })
                    curr_page += 1
            save_to_db("seven_eleven", all_items)
            await browser.close()
            return f"ì„¸ë¸ì¼ë ˆë¸ ì™„ë£Œ: {len(all_items)}ê°œ"
        except Exception as e:
            await browser.close()
            return f"ì„¸ë¸ì¼ë ˆë¸ ì—ëŸ¬: {e}"

# --- ìŠ¤ì¼€ì¥´ë§ ---
async def run_full_pipeline(stores):
    """
    íŠ¹ì • ë§¤ì¥ë“¤ì— ëŒ€í•´ ìˆ˜ì§‘ ë° Enrich ì‘ì—…ì„ ìˆœì°¨ì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    print(f"\n--- ğŸ”„ ì‘ì—… ì‹œì‘: {', '.join(stores)} ---")
    
    # 1ë‹¨ê³„: ìˆ˜ì§‘ (í¬ë¡¤ë§)
    tasks = []
    if "gs_the_fresh" in stores: tasks.append(get_gs_the_fresh_deals())
    if "emart" in stores: tasks.append(get_emart_deals())
    if "cu" in stores: tasks.append(get_cu_deals())
    if "gs25" in stores: tasks.append(get_gs25_deals())
    if "seven_eleven" in stores: tasks.append(get_seven_eleven_deals())
    
    if tasks:
        print(f"ğŸš€ [1ë‹¨ê³„] {len(tasks)}ê°œ ë§¤ì¥ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        results = await asyncio.gather(*tasks)
        for res in results:
            print(f"  > {res}")

    # 2ë‹¨ê³„: AI Enrich (íƒœê¹…)
    print("\nâœ¨ [2ë‹¨ê³„] AI Enrich(íƒœê¹…) ì‘ì—… ì‹œì‘...")
    for store in stores:
        try:
            enrich_result = await enrich_db_with_tags_high_speed(store)
            print(f"  > âœ… {store}: {enrich_result}")
        except Exception as e:
            print(f"  > âŒ {store} íƒœê¹… ì¤‘ ì˜¤ë¥˜: {e}")
            
    print(f"--- âœ… ì‘ì—… ì™„ë£Œ: {', '.join(stores)} ---\n")

# --- ë©”ì¸ ì‹¤í–‰ë¶€ (ìŠ¤ì¼€ì¥´ëŸ¬) ---
async def main():
    scheduler = AsyncIOScheduler()

    # [ìŠ¤ì¼€ì¤„ 1] í¸ì˜ì  (CU, GS25, 7-11) - ë§¤ì›” 1ì¼ ìƒˆë²½ 1ì‹œ
    # '0 1 1 * *'
    scheduler.add_job(
        run_full_pipeline,
        CronTrigger(day="1", hour="1", minute="0"),
        args=[["cu", "gs25", "seven_eleven"]],
        name="Monthly_Convenience_Stores"
    )

    # [ìŠ¤ì¼€ì¤„ 2] GS ë”í”„ë ˆì‹œ - ë§¤ì£¼ ìˆ˜ìš”ì¼ ìƒˆë²½ 1ì‹œ
    # '0 1 * * 2' (0:ì›”, 1:í™”, 2:ìˆ˜...)
    scheduler.add_job(
        run_full_pipeline,
        CronTrigger(day_of_week="wed", hour="1", minute="0"),
        args=[["gs_the_fresh"]],
        name="Weekly_GS_The_Fresh"
    )

    # [ìŠ¤ì¼€ì¤„ 3] ì´ë§ˆíŠ¸ - ë§¤ì£¼ ëª©ìš”ì¼ ìƒˆë²½ 1ì‹œ
    scheduler.add_job(
        run_full_pipeline,
        CronTrigger(day_of_week="thu", hour="1", minute="0"),
        args=[["emart"]],
        name="Weekly_Emart"
    )

    scheduler.start()
    print("â° ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("  - ë§¤ì›” 1ì¼ 01:00: í¸ì˜ì  3ì‚¬")
    print("  - ë§¤ì£¼ ìˆ˜ìš”ì¼ 01:00: GS ë”í”„ë ˆì‹œ")
    print("  - ë§¤ì£¼ ëª©ìš”ì¼ 01:00: ì´ë§ˆíŠ¸")

    # ìˆ˜ë™ ì‹¤í–‰ ëª¨ë“œ ì²˜ë¦¬
    if len(sys.argv) > 1 and sys.argv[1] == "--manual":
        target_store = sys.argv[2:] if len(sys.argv) > 2 else ["gs_the_fresh", "cu", "gs25", "seven_eleven", "emart"]
        print(f"\nâš¡ ìˆ˜ë™ ì‹¤í–‰ ëª¨ë“œ ê°ì§€: {target_store} ì‘ì—…ì„ ì¦‰ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        await run_full_pipeline(target_store)

    # ì„œë²„ê°€ ì¢…ë£Œë˜ì§€ ì•Šë„ë¡ ë¬´í•œ ëŒ€ê¸°
    try:
        while True:
            await asyncio.sleep(1000)
    except (KeyboardInterrupt, SystemExit):
        scheduler.shutdown()

if __name__ == "__main__":
    # ë¹„ë™ê¸° ì‹¤í–‰
    asyncio.run(main())